---
title: 'Conference paper (Springer)'

# Authors
# If you created a profile for a user (e.g. the default `admin` user), write the username (folder name) here
# and it will be replaced with their full name and linked to their profile.
authors:
  - Md. Imran Khan
  - Dr. Ahmed Wasif Reza

# Author notes (optional)
author_notes:
  - 'Equal contribution'
  - 'Equal contribution'

date: 

# Schedule page publish date (NOT publication's date).
publishDate: '2025-03-01T00:00:00Z'

# Publication type.
# Accepts a single type but formatted as a YAML list (for Hugo requirements).
# Enter a publication type from the CSL standard.
publication_types: ['paper-conference']

# Publication name and optional abbreviated publication name.
publication: In *CIIR2025*
publication_short: In *CIIR*

abstract:  The integration of renewable energy sources into power grids presents significant challenges in forecasting and optimization due to their intermittent nature and complex spatial-temporal dependencies. This paper proposes a novel Transformer encoder-based model that effectively addresses key challenges in renewable energy forecasting and grid management. Our approach leverages multi-head self-attention mechanisms to capture long-range dependencies in weather patterns, energy consumption data, and grid operational parameters. Experimental results demonstrate superior performance compared to state-of-the-art methods, including LSTM networks and traditional statistical models, across multiple evaluation metrics. The proposed model achieves significant improvements in prediction accuracy for solar energy generation and grid load forecasting, enabling more efficient energy distribution and reduced operational costs.

# Summary. An optional shortened abstract.
summary: A Transformer-based model for renewable energy forecasting that outperforms existing approaches, addressing key challenges in solar grid efficiency through advanced attention mechanisms.

tags:
  - Large Language Models
  

# Display this page in the Featured widget?
featured: true

# Standard identifiers for auto-linking
hugoblox:
  ids:
    doi: 10.5555/123456

# Custom links
links:
  - type: pdf
    url: ""
  - type: code
    url: https://github.com/HugoBlox/hugo-blox-builder
  - type: dataset
    url: https://github.com/HugoBlox/hugo-blox-builder
  - type: slides
    url: https://www.slideshare.net/
  - type: source
    url: https://github.com/HugoBlox/hugo-blox-builder
  - type: video
    url: https://youtube.com

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
image:
  caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/pLCdAaMFLTE)'
  focal_point: ''
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects:
  - example

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ""
---

> [!NOTE]
> Click the _Cite_ button above to demo the feature to enable visitors to import publication metadata into their reference management software.

> [!NOTE]
> Create your slides in Markdown - click the _Slides_ button to check out the example.

Add the publication's **full text** or **supplementary notes** here. You can use rich formatting such as including [code, math, and images](https://docs.hugoblox.com/content/writing-markdown-latex/).
